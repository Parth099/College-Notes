# 1.1 Simulation of Discrete Probabilities
For: [[Probability Theory 1]]
## Probability
We will first consider experiments with an finite number of outcomes labeled $w_1, w_2, \dotso, w_n$ like rolling a dice or a coin flip.

Lets say we want to track the sum of 4 dice rolls.
We can use the *random variables* $X_i$. They are just an functional expression for the outcome of an experiment. This definition will be extended in [[Random Variable]]

$$X_1 + X_2 + X_3 + X_4$$

Lets assign probabilities to the possible outcomes of this experiment. Recall they were assigned the letter $w$. We assign each $w_j$ a non-negative number $m(w_j)$ such that.
$$\sum_{k = 1}^{6} m(w_k) = \boxed{1}$$
Just a fancy way of saying the sum of all probabilities is **1**.

This function $m_(w_j)$ is called the *distribution function* of the random var X. Each functional output is $\frac{1}{6}$.
We can write that 
$$P(X \leq 4) = \frac{2}{3}$$


## Simulation
The lesson to be learned here is that 
>Accurate results by simulation require a large number of experiments.

### Examples

#### Example A
Is it favorable to bet that in 4 rolls at least one 6 would show up.
The chance of a roll not being is 6 is $\frac{5}{6}$

The chance of not rolling 6 two times is $(\frac{5}{6})^2$
By this logic four roles ends up to be: 
$$1 - (\frac{5}{6})^4$$
which is $.518$

We can think of this calculation as this:
>The probability of rolling any number minus the probability of getting of getting any number thats not 6.

This example can be adapted to a situation where $n$ dice are rolled at the same time and we want to see how many of them will be all sixes
$$ 1 - (\frac{6^n-1}{6^n})^m$$ 
$m$ is the times we roll.

