{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ev7mKEvgbYcZ"
   },
   "source": [
    "# Lab 10: Fully Connected Neural Networks\n",
    "\n",
    "In this assignment, we will learn fully connected neural network. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vwZwfFQYbYcc"
   },
   "source": [
    "## 1. Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WHnoQz3MbYcd"
   },
   "source": [
    "This assignement should be run on Google Colab where you can use free GPU to accelerate the computation. Please refer to our slides to set up GPU. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u4Rte_TebYce"
   },
   "source": [
    "### 1. Install Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6583,
     "status": "ok",
     "timestamp": 1649559863527,
     "user": {
      "displayName": "hongchang gao",
      "userId": "17845522714326773021"
     },
     "user_tz": 240
    },
    "id": "5YjZrt3dW4SB",
    "outputId": "3ff45b08-cc1c-4281-b8a8-f31d06275642"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.11.1+cu111)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.10.0.2)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.21.5)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision   # install pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cqu1YdX2bYch"
   },
   "source": [
    "### 2. Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 180,
     "status": "ok",
     "timestamp": 1649559865200,
     "user": {
      "displayName": "hongchang gao",
      "userId": "17845522714326773021"
     },
     "user_tz": 240
    },
    "id": "KH1pKuAAXqzd",
    "outputId": "6987f9ee-b3ff-43c5-d4ea-4cd7d2a1ee5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Apr 10 03:04:26 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   34C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!/opt/bin/nvidia-smi  #show GPU "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bqmII1sAbYcj"
   },
   "source": [
    "### 3. Mount to google drive (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17744,
     "status": "ok",
     "timestamp": 1649274810388,
     "user": {
      "displayName": "hongchang gao",
      "userId": "17845522714326773021"
     },
     "user_tz": 240
    },
    "id": "HdWuV25Qb-TM",
    "outputId": "09e93d6a-5e99-4510-e3be-eca9853e6566"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_bAPbFl0bYck"
   },
   "source": [
    "### 4. Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-nVVA8yeXv9c"
   },
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eTnQJNfyhmaE"
   },
   "outputs": [],
   "source": [
    "args={}\n",
    "args['batch_size']=100\n",
    "args['test_batch_size']=100\n",
    "args['epochs']=10  #The number of Epochs is the number of times you go through the full dataset. \n",
    "args['lr']=0.01 #Learning rate is how fast it will decend. \n",
    "args['log_interval']=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 127,
     "status": "ok",
     "timestamp": 1649276322480,
     "user": {
      "displayName": "hongchang gao",
      "userId": "17845522714326773021"
     },
     "user_tz": 240
    },
    "id": "4aMP_CHcX7jJ",
    "outputId": "7d252d46-624d-4416-9851-8cdff1ce97da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# build an mlp\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(28*28, 256)   # linear layer (784 -> 256)\n",
    "        self.fc2 = nn.Linear(256,128)  # linear layer (256 -> 128)\n",
    "        self.fc3 = nn.Linear(128,10)  # linear layer (128 -> 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = x.view(-1,28*28) #input layer\n",
    "        h1 = F.relu(self.fc1(h0)) # hidden layer 1\n",
    "        h2 = F.relu(self.fc2(h1)) # hidden layer 2\n",
    "        h3 = self.fc3(h2) # output layer\n",
    "\n",
    "        return h3\n",
    "\n",
    "model = Net()\n",
    "model.cuda() # put the model on GPU\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0U9yHGoTZi3e"
   },
   "outputs": [],
   "source": [
    "# loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr = args['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YvuVjPqPabRC"
   },
   "outputs": [],
   "source": [
    "#load the data\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('./data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=args['batch_size'], shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('./data', train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=args['test_batch_size'], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YopP0oK5ca2u"
   },
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "        \n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # compute gradients\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        #to do a one-step update on our parameter.\n",
    "        optimizer.step()\n",
    "\n",
    "        #Print out the loss periodically. \n",
    "        if batch_idx % args['log_interval'] == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wLn-uP_sct-a"
   },
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "\n",
    "        output = model(data)\n",
    "        test_loss += criterion(output, target).item() # sum up batch loss\n",
    "        pred = output.data.max(1, keepdim=True)[1] \n",
    "        correct += pred.eq(target.data.view_as(pred)).long().cpu().sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 158181,
     "status": "ok",
     "timestamp": 1649276492527,
     "user": {
      "displayName": "hongchang gao",
      "userId": "17845522714326773021"
     },
     "user_tz": 240
    },
    "id": "FgF4zxVlc28U",
    "outputId": "aaa6553d-5c92-4714-db39-37f12e88f997"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.294220\n",
      "Train Epoch: 1 [1000/60000 (2%)]\tLoss: 2.282000\n",
      "Train Epoch: 1 [2000/60000 (3%)]\tLoss: 2.273644\n",
      "Train Epoch: 1 [3000/60000 (5%)]\tLoss: 2.253926\n",
      "Train Epoch: 1 [4000/60000 (7%)]\tLoss: 2.222272\n",
      "Train Epoch: 1 [5000/60000 (8%)]\tLoss: 2.234466\n",
      "Train Epoch: 1 [6000/60000 (10%)]\tLoss: 2.183182\n",
      "Train Epoch: 1 [7000/60000 (12%)]\tLoss: 2.202102\n",
      "Train Epoch: 1 [8000/60000 (13%)]\tLoss: 2.170457\n",
      "Train Epoch: 1 [9000/60000 (15%)]\tLoss: 2.145060\n",
      "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 2.061340\n",
      "Train Epoch: 1 [11000/60000 (18%)]\tLoss: 2.043314\n",
      "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 2.060695\n",
      "Train Epoch: 1 [13000/60000 (22%)]\tLoss: 1.988743\n",
      "Train Epoch: 1 [14000/60000 (23%)]\tLoss: 1.892585\n",
      "Train Epoch: 1 [15000/60000 (25%)]\tLoss: 1.740298\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 1.847932\n",
      "Train Epoch: 1 [17000/60000 (28%)]\tLoss: 1.662120\n",
      "Train Epoch: 1 [18000/60000 (30%)]\tLoss: 1.725761\n",
      "Train Epoch: 1 [19000/60000 (32%)]\tLoss: 1.626114\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 1.573845\n",
      "Train Epoch: 1 [21000/60000 (35%)]\tLoss: 1.471452\n",
      "Train Epoch: 1 [22000/60000 (37%)]\tLoss: 1.237249\n",
      "Train Epoch: 1 [23000/60000 (38%)]\tLoss: 1.344255\n",
      "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 1.181402\n",
      "Train Epoch: 1 [25000/60000 (42%)]\tLoss: 1.110066\n",
      "Train Epoch: 1 [26000/60000 (43%)]\tLoss: 1.129123\n",
      "Train Epoch: 1 [27000/60000 (45%)]\tLoss: 1.081240\n",
      "Train Epoch: 1 [28000/60000 (47%)]\tLoss: 1.096296\n",
      "Train Epoch: 1 [29000/60000 (48%)]\tLoss: 0.996874\n",
      "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 1.006476\n",
      "Train Epoch: 1 [31000/60000 (52%)]\tLoss: 0.994955\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 1.043508\n",
      "Train Epoch: 1 [33000/60000 (55%)]\tLoss: 1.033678\n",
      "Train Epoch: 1 [34000/60000 (57%)]\tLoss: 0.946621\n",
      "Train Epoch: 1 [35000/60000 (58%)]\tLoss: 0.770046\n",
      "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.841537\n",
      "Train Epoch: 1 [37000/60000 (62%)]\tLoss: 0.825619\n",
      "Train Epoch: 1 [38000/60000 (63%)]\tLoss: 0.764735\n",
      "Train Epoch: 1 [39000/60000 (65%)]\tLoss: 1.097367\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 0.876044\n",
      "Train Epoch: 1 [41000/60000 (68%)]\tLoss: 0.866943\n",
      "Train Epoch: 1 [42000/60000 (70%)]\tLoss: 1.035696\n",
      "Train Epoch: 1 [43000/60000 (72%)]\tLoss: 0.826145\n",
      "Train Epoch: 1 [44000/60000 (73%)]\tLoss: 0.697534\n",
      "Train Epoch: 1 [45000/60000 (75%)]\tLoss: 0.865282\n",
      "Train Epoch: 1 [46000/60000 (77%)]\tLoss: 0.786874\n",
      "Train Epoch: 1 [47000/60000 (78%)]\tLoss: 0.624064\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.753833\n",
      "Train Epoch: 1 [49000/60000 (82%)]\tLoss: 0.765965\n",
      "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 0.670515\n",
      "Train Epoch: 1 [51000/60000 (85%)]\tLoss: 0.729593\n",
      "Train Epoch: 1 [52000/60000 (87%)]\tLoss: 0.719995\n",
      "Train Epoch: 1 [53000/60000 (88%)]\tLoss: 0.782379\n",
      "Train Epoch: 1 [54000/60000 (90%)]\tLoss: 0.964704\n",
      "Train Epoch: 1 [55000/60000 (92%)]\tLoss: 0.918544\n",
      "Train Epoch: 1 [56000/60000 (93%)]\tLoss: 0.793175\n",
      "Train Epoch: 1 [57000/60000 (95%)]\tLoss: 0.716506\n",
      "Train Epoch: 1 [58000/60000 (97%)]\tLoss: 0.676923\n",
      "Train Epoch: 1 [59000/60000 (98%)]\tLoss: 0.868590\n",
      "\n",
      "Test set: Average loss: 0.0067, Accuracy: 8109/10000 (81%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.745766\n",
      "Train Epoch: 2 [1000/60000 (2%)]\tLoss: 0.515798\n",
      "Train Epoch: 2 [2000/60000 (3%)]\tLoss: 0.560053\n",
      "Train Epoch: 2 [3000/60000 (5%)]\tLoss: 0.683030\n",
      "Train Epoch: 2 [4000/60000 (7%)]\tLoss: 0.619786\n",
      "Train Epoch: 2 [5000/60000 (8%)]\tLoss: 0.683501\n",
      "Train Epoch: 2 [6000/60000 (10%)]\tLoss: 0.642645\n",
      "Train Epoch: 2 [7000/60000 (12%)]\tLoss: 0.509967\n",
      "Train Epoch: 2 [8000/60000 (13%)]\tLoss: 0.638535\n",
      "Train Epoch: 2 [9000/60000 (15%)]\tLoss: 0.660688\n",
      "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 0.948823\n",
      "Train Epoch: 2 [11000/60000 (18%)]\tLoss: 0.738849\n",
      "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.598338\n",
      "Train Epoch: 2 [13000/60000 (22%)]\tLoss: 0.822017\n",
      "Train Epoch: 2 [14000/60000 (23%)]\tLoss: 0.694972\n",
      "Train Epoch: 2 [15000/60000 (25%)]\tLoss: 0.637460\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.619392\n",
      "Train Epoch: 2 [17000/60000 (28%)]\tLoss: 0.809681\n",
      "Train Epoch: 2 [18000/60000 (30%)]\tLoss: 0.445577\n",
      "Train Epoch: 2 [19000/60000 (32%)]\tLoss: 0.617048\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 0.556344\n",
      "Train Epoch: 2 [21000/60000 (35%)]\tLoss: 0.821001\n",
      "Train Epoch: 2 [22000/60000 (37%)]\tLoss: 0.475678\n",
      "Train Epoch: 2 [23000/60000 (38%)]\tLoss: 0.521483\n",
      "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.475716\n",
      "Train Epoch: 2 [25000/60000 (42%)]\tLoss: 0.834900\n",
      "Train Epoch: 2 [26000/60000 (43%)]\tLoss: 0.521631\n",
      "Train Epoch: 2 [27000/60000 (45%)]\tLoss: 0.600080\n",
      "Train Epoch: 2 [28000/60000 (47%)]\tLoss: 0.525988\n",
      "Train Epoch: 2 [29000/60000 (48%)]\tLoss: 0.412471\n",
      "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 0.490934\n",
      "Train Epoch: 2 [31000/60000 (52%)]\tLoss: 0.562046\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.449944\n",
      "Train Epoch: 2 [33000/60000 (55%)]\tLoss: 0.720961\n",
      "Train Epoch: 2 [34000/60000 (57%)]\tLoss: 0.636882\n",
      "Train Epoch: 2 [35000/60000 (58%)]\tLoss: 0.282764\n",
      "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.532682\n",
      "Train Epoch: 2 [37000/60000 (62%)]\tLoss: 0.354546\n",
      "Train Epoch: 2 [38000/60000 (63%)]\tLoss: 0.593879\n",
      "Train Epoch: 2 [39000/60000 (65%)]\tLoss: 0.464515\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 0.593979\n",
      "Train Epoch: 2 [41000/60000 (68%)]\tLoss: 0.640794\n",
      "Train Epoch: 2 [42000/60000 (70%)]\tLoss: 0.711594\n",
      "Train Epoch: 2 [43000/60000 (72%)]\tLoss: 0.712438\n",
      "Train Epoch: 2 [44000/60000 (73%)]\tLoss: 0.552333\n",
      "Train Epoch: 2 [45000/60000 (75%)]\tLoss: 0.533041\n",
      "Train Epoch: 2 [46000/60000 (77%)]\tLoss: 0.609731\n",
      "Train Epoch: 2 [47000/60000 (78%)]\tLoss: 0.457542\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.468745\n",
      "Train Epoch: 2 [49000/60000 (82%)]\tLoss: 0.482584\n",
      "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 0.391495\n",
      "Train Epoch: 2 [51000/60000 (85%)]\tLoss: 0.610730\n",
      "Train Epoch: 2 [52000/60000 (87%)]\tLoss: 0.571492\n",
      "Train Epoch: 2 [53000/60000 (88%)]\tLoss: 0.753837\n",
      "Train Epoch: 2 [54000/60000 (90%)]\tLoss: 0.467404\n",
      "Train Epoch: 2 [55000/60000 (92%)]\tLoss: 0.562400\n",
      "Train Epoch: 2 [56000/60000 (93%)]\tLoss: 0.448338\n",
      "Train Epoch: 2 [57000/60000 (95%)]\tLoss: 0.512386\n",
      "Train Epoch: 2 [58000/60000 (97%)]\tLoss: 0.413182\n",
      "Train Epoch: 2 [59000/60000 (98%)]\tLoss: 0.478029\n",
      "\n",
      "Test set: Average loss: 0.0054, Accuracy: 8273/10000 (83%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.682503\n",
      "Train Epoch: 3 [1000/60000 (2%)]\tLoss: 0.562633\n",
      "Train Epoch: 3 [2000/60000 (3%)]\tLoss: 0.526377\n",
      "Train Epoch: 3 [3000/60000 (5%)]\tLoss: 0.320283\n",
      "Train Epoch: 3 [4000/60000 (7%)]\tLoss: 0.686727\n",
      "Train Epoch: 3 [5000/60000 (8%)]\tLoss: 0.367632\n",
      "Train Epoch: 3 [6000/60000 (10%)]\tLoss: 0.501230\n",
      "Train Epoch: 3 [7000/60000 (12%)]\tLoss: 0.420730\n",
      "Train Epoch: 3 [8000/60000 (13%)]\tLoss: 0.499689\n",
      "Train Epoch: 3 [9000/60000 (15%)]\tLoss: 0.534862\n",
      "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 0.343126\n",
      "Train Epoch: 3 [11000/60000 (18%)]\tLoss: 0.421588\n",
      "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 0.472400\n",
      "Train Epoch: 3 [13000/60000 (22%)]\tLoss: 0.687715\n",
      "Train Epoch: 3 [14000/60000 (23%)]\tLoss: 0.540121\n",
      "Train Epoch: 3 [15000/60000 (25%)]\tLoss: 0.438914\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.527948\n",
      "Train Epoch: 3 [17000/60000 (28%)]\tLoss: 0.433731\n",
      "Train Epoch: 3 [18000/60000 (30%)]\tLoss: 0.583262\n",
      "Train Epoch: 3 [19000/60000 (32%)]\tLoss: 0.591320\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 0.873738\n",
      "Train Epoch: 3 [21000/60000 (35%)]\tLoss: 0.562595\n",
      "Train Epoch: 3 [22000/60000 (37%)]\tLoss: 0.565617\n",
      "Train Epoch: 3 [23000/60000 (38%)]\tLoss: 0.510365\n",
      "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.362317\n",
      "Train Epoch: 3 [25000/60000 (42%)]\tLoss: 0.574384\n",
      "Train Epoch: 3 [26000/60000 (43%)]\tLoss: 0.518499\n",
      "Train Epoch: 3 [27000/60000 (45%)]\tLoss: 0.487641\n",
      "Train Epoch: 3 [28000/60000 (47%)]\tLoss: 0.533482\n",
      "Train Epoch: 3 [29000/60000 (48%)]\tLoss: 0.393077\n",
      "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 0.557564\n",
      "Train Epoch: 3 [31000/60000 (52%)]\tLoss: 0.487775\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.565079\n",
      "Train Epoch: 3 [33000/60000 (55%)]\tLoss: 0.417141\n",
      "Train Epoch: 3 [34000/60000 (57%)]\tLoss: 0.433343\n",
      "Train Epoch: 3 [35000/60000 (58%)]\tLoss: 0.510193\n",
      "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 0.435699\n",
      "Train Epoch: 3 [37000/60000 (62%)]\tLoss: 0.590610\n",
      "Train Epoch: 3 [38000/60000 (63%)]\tLoss: 0.341471\n",
      "Train Epoch: 3 [39000/60000 (65%)]\tLoss: 0.597971\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 0.538706\n",
      "Train Epoch: 3 [41000/60000 (68%)]\tLoss: 0.370492\n",
      "Train Epoch: 3 [42000/60000 (70%)]\tLoss: 0.469518\n",
      "Train Epoch: 3 [43000/60000 (72%)]\tLoss: 0.670365\n",
      "Train Epoch: 3 [44000/60000 (73%)]\tLoss: 0.532584\n",
      "Train Epoch: 3 [45000/60000 (75%)]\tLoss: 0.333173\n",
      "Train Epoch: 3 [46000/60000 (77%)]\tLoss: 0.375298\n",
      "Train Epoch: 3 [47000/60000 (78%)]\tLoss: 0.441800\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.556794\n",
      "Train Epoch: 3 [49000/60000 (82%)]\tLoss: 0.706663\n",
      "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 0.356766\n",
      "Train Epoch: 3 [51000/60000 (85%)]\tLoss: 0.366483\n",
      "Train Epoch: 3 [52000/60000 (87%)]\tLoss: 0.421325\n",
      "Train Epoch: 3 [53000/60000 (88%)]\tLoss: 0.451238\n",
      "Train Epoch: 3 [54000/60000 (90%)]\tLoss: 0.649500\n",
      "Train Epoch: 3 [55000/60000 (92%)]\tLoss: 0.427020\n",
      "Train Epoch: 3 [56000/60000 (93%)]\tLoss: 0.479150\n",
      "Train Epoch: 3 [57000/60000 (95%)]\tLoss: 0.585468\n",
      "Train Epoch: 3 [58000/60000 (97%)]\tLoss: 0.605418\n",
      "Train Epoch: 3 [59000/60000 (98%)]\tLoss: 0.299781\n",
      "\n",
      "Test set: Average loss: 0.0049, Accuracy: 8392/10000 (84%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.398488\n",
      "Train Epoch: 4 [1000/60000 (2%)]\tLoss: 0.613475\n",
      "Train Epoch: 4 [2000/60000 (3%)]\tLoss: 0.438549\n",
      "Train Epoch: 4 [3000/60000 (5%)]\tLoss: 0.502982\n",
      "Train Epoch: 4 [4000/60000 (7%)]\tLoss: 0.686764\n",
      "Train Epoch: 4 [5000/60000 (8%)]\tLoss: 0.557340\n",
      "Train Epoch: 4 [6000/60000 (10%)]\tLoss: 0.397561\n",
      "Train Epoch: 4 [7000/60000 (12%)]\tLoss: 0.599175\n",
      "Train Epoch: 4 [8000/60000 (13%)]\tLoss: 0.559603\n",
      "Train Epoch: 4 [9000/60000 (15%)]\tLoss: 0.552687\n",
      "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 0.375013\n",
      "Train Epoch: 4 [11000/60000 (18%)]\tLoss: 0.476052\n",
      "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 0.555459\n",
      "Train Epoch: 4 [13000/60000 (22%)]\tLoss: 0.437979\n",
      "Train Epoch: 4 [14000/60000 (23%)]\tLoss: 0.617149\n",
      "Train Epoch: 4 [15000/60000 (25%)]\tLoss: 0.459544\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.346489\n",
      "Train Epoch: 4 [17000/60000 (28%)]\tLoss: 0.586255\n",
      "Train Epoch: 4 [18000/60000 (30%)]\tLoss: 0.507571\n",
      "Train Epoch: 4 [19000/60000 (32%)]\tLoss: 0.573149\n",
      "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 0.562205\n",
      "Train Epoch: 4 [21000/60000 (35%)]\tLoss: 0.472135\n",
      "Train Epoch: 4 [22000/60000 (37%)]\tLoss: 0.405364\n",
      "Train Epoch: 4 [23000/60000 (38%)]\tLoss: 0.439027\n",
      "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 0.483741\n",
      "Train Epoch: 4 [25000/60000 (42%)]\tLoss: 0.511403\n",
      "Train Epoch: 4 [26000/60000 (43%)]\tLoss: 0.472593\n",
      "Train Epoch: 4 [27000/60000 (45%)]\tLoss: 0.710015\n",
      "Train Epoch: 4 [28000/60000 (47%)]\tLoss: 0.605228\n",
      "Train Epoch: 4 [29000/60000 (48%)]\tLoss: 0.316282\n",
      "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 0.434337\n",
      "Train Epoch: 4 [31000/60000 (52%)]\tLoss: 0.634071\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.480229\n",
      "Train Epoch: 4 [33000/60000 (55%)]\tLoss: 0.422043\n",
      "Train Epoch: 4 [34000/60000 (57%)]\tLoss: 0.562273\n",
      "Train Epoch: 4 [35000/60000 (58%)]\tLoss: 0.508558\n",
      "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 0.607123\n",
      "Train Epoch: 4 [37000/60000 (62%)]\tLoss: 0.390009\n",
      "Train Epoch: 4 [38000/60000 (63%)]\tLoss: 0.377997\n",
      "Train Epoch: 4 [39000/60000 (65%)]\tLoss: 0.279322\n",
      "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 0.340586\n",
      "Train Epoch: 4 [41000/60000 (68%)]\tLoss: 0.414972\n",
      "Train Epoch: 4 [42000/60000 (70%)]\tLoss: 0.354041\n",
      "Train Epoch: 4 [43000/60000 (72%)]\tLoss: 0.284088\n",
      "Train Epoch: 4 [44000/60000 (73%)]\tLoss: 0.487697\n",
      "Train Epoch: 4 [45000/60000 (75%)]\tLoss: 0.552330\n",
      "Train Epoch: 4 [46000/60000 (77%)]\tLoss: 0.468135\n",
      "Train Epoch: 4 [47000/60000 (78%)]\tLoss: 0.475847\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.441475\n",
      "Train Epoch: 4 [49000/60000 (82%)]\tLoss: 0.501850\n",
      "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 0.632453\n",
      "Train Epoch: 4 [51000/60000 (85%)]\tLoss: 0.560287\n",
      "Train Epoch: 4 [52000/60000 (87%)]\tLoss: 0.516076\n",
      "Train Epoch: 4 [53000/60000 (88%)]\tLoss: 0.592400\n",
      "Train Epoch: 4 [54000/60000 (90%)]\tLoss: 0.532262\n",
      "Train Epoch: 4 [55000/60000 (92%)]\tLoss: 0.382307\n",
      "Train Epoch: 4 [56000/60000 (93%)]\tLoss: 0.376608\n",
      "Train Epoch: 4 [57000/60000 (95%)]\tLoss: 0.474759\n",
      "Train Epoch: 4 [58000/60000 (97%)]\tLoss: 0.461638\n",
      "Train Epoch: 4 [59000/60000 (98%)]\tLoss: 0.473115\n",
      "\n",
      "Test set: Average loss: 0.0046, Accuracy: 8458/10000 (85%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.626879\n",
      "Train Epoch: 5 [1000/60000 (2%)]\tLoss: 0.462873\n",
      "Train Epoch: 5 [2000/60000 (3%)]\tLoss: 0.485497\n",
      "Train Epoch: 5 [3000/60000 (5%)]\tLoss: 0.369287\n",
      "Train Epoch: 5 [4000/60000 (7%)]\tLoss: 0.505770\n",
      "Train Epoch: 5 [5000/60000 (8%)]\tLoss: 0.455145\n",
      "Train Epoch: 5 [6000/60000 (10%)]\tLoss: 0.373622\n",
      "Train Epoch: 5 [7000/60000 (12%)]\tLoss: 0.272735\n",
      "Train Epoch: 5 [8000/60000 (13%)]\tLoss: 0.598864\n",
      "Train Epoch: 5 [9000/60000 (15%)]\tLoss: 0.385728\n",
      "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 0.437482\n",
      "Train Epoch: 5 [11000/60000 (18%)]\tLoss: 0.342943\n",
      "Train Epoch: 5 [12000/60000 (20%)]\tLoss: 0.383546\n",
      "Train Epoch: 5 [13000/60000 (22%)]\tLoss: 0.456432\n",
      "Train Epoch: 5 [14000/60000 (23%)]\tLoss: 0.488677\n",
      "Train Epoch: 5 [15000/60000 (25%)]\tLoss: 0.457545\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.522015\n",
      "Train Epoch: 5 [17000/60000 (28%)]\tLoss: 0.394722\n",
      "Train Epoch: 5 [18000/60000 (30%)]\tLoss: 0.324466\n",
      "Train Epoch: 5 [19000/60000 (32%)]\tLoss: 0.532089\n",
      "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 0.488985\n",
      "Train Epoch: 5 [21000/60000 (35%)]\tLoss: 0.398956\n",
      "Train Epoch: 5 [22000/60000 (37%)]\tLoss: 0.591558\n",
      "Train Epoch: 5 [23000/60000 (38%)]\tLoss: 0.493755\n",
      "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 0.445908\n",
      "Train Epoch: 5 [25000/60000 (42%)]\tLoss: 0.476009\n",
      "Train Epoch: 5 [26000/60000 (43%)]\tLoss: 0.566931\n",
      "Train Epoch: 5 [27000/60000 (45%)]\tLoss: 0.455566\n",
      "Train Epoch: 5 [28000/60000 (47%)]\tLoss: 0.441973\n",
      "Train Epoch: 5 [29000/60000 (48%)]\tLoss: 0.538315\n",
      "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 0.434291\n",
      "Train Epoch: 5 [31000/60000 (52%)]\tLoss: 0.495766\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.454387\n",
      "Train Epoch: 5 [33000/60000 (55%)]\tLoss: 0.396489\n",
      "Train Epoch: 5 [34000/60000 (57%)]\tLoss: 0.620176\n",
      "Train Epoch: 5 [35000/60000 (58%)]\tLoss: 0.441841\n",
      "Train Epoch: 5 [36000/60000 (60%)]\tLoss: 0.331385\n",
      "Train Epoch: 5 [37000/60000 (62%)]\tLoss: 0.576691\n",
      "Train Epoch: 5 [38000/60000 (63%)]\tLoss: 0.531842\n",
      "Train Epoch: 5 [39000/60000 (65%)]\tLoss: 0.250184\n",
      "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 0.472163\n",
      "Train Epoch: 5 [41000/60000 (68%)]\tLoss: 0.374578\n",
      "Train Epoch: 5 [42000/60000 (70%)]\tLoss: 0.463920\n",
      "Train Epoch: 5 [43000/60000 (72%)]\tLoss: 0.361707\n",
      "Train Epoch: 5 [44000/60000 (73%)]\tLoss: 0.563516\n",
      "Train Epoch: 5 [45000/60000 (75%)]\tLoss: 0.360402\n",
      "Train Epoch: 5 [46000/60000 (77%)]\tLoss: 0.359711\n",
      "Train Epoch: 5 [47000/60000 (78%)]\tLoss: 0.388635\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.436122\n",
      "Train Epoch: 5 [49000/60000 (82%)]\tLoss: 0.479111\n",
      "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 0.413565\n",
      "Train Epoch: 5 [51000/60000 (85%)]\tLoss: 0.475023\n",
      "Train Epoch: 5 [52000/60000 (87%)]\tLoss: 0.535922\n",
      "Train Epoch: 5 [53000/60000 (88%)]\tLoss: 0.468434\n",
      "Train Epoch: 5 [54000/60000 (90%)]\tLoss: 0.496867\n",
      "Train Epoch: 5 [55000/60000 (92%)]\tLoss: 0.458689\n",
      "Train Epoch: 5 [56000/60000 (93%)]\tLoss: 0.520981\n",
      "Train Epoch: 5 [57000/60000 (95%)]\tLoss: 0.423262\n",
      "Train Epoch: 5 [58000/60000 (97%)]\tLoss: 0.403087\n",
      "Train Epoch: 5 [59000/60000 (98%)]\tLoss: 0.519453\n",
      "\n",
      "Test set: Average loss: 0.0044, Accuracy: 8502/10000 (85%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.336025\n",
      "Train Epoch: 6 [1000/60000 (2%)]\tLoss: 0.370255\n",
      "Train Epoch: 6 [2000/60000 (3%)]\tLoss: 0.355279\n",
      "Train Epoch: 6 [3000/60000 (5%)]\tLoss: 0.413976\n",
      "Train Epoch: 6 [4000/60000 (7%)]\tLoss: 0.442488\n",
      "Train Epoch: 6 [5000/60000 (8%)]\tLoss: 0.325526\n",
      "Train Epoch: 6 [6000/60000 (10%)]\tLoss: 0.612634\n",
      "Train Epoch: 6 [7000/60000 (12%)]\tLoss: 0.474659\n",
      "Train Epoch: 6 [8000/60000 (13%)]\tLoss: 0.529642\n",
      "Train Epoch: 6 [9000/60000 (15%)]\tLoss: 0.337348\n",
      "Train Epoch: 6 [10000/60000 (17%)]\tLoss: 0.401474\n",
      "Train Epoch: 6 [11000/60000 (18%)]\tLoss: 0.321167\n",
      "Train Epoch: 6 [12000/60000 (20%)]\tLoss: 0.324330\n",
      "Train Epoch: 6 [13000/60000 (22%)]\tLoss: 0.512072\n",
      "Train Epoch: 6 [14000/60000 (23%)]\tLoss: 0.245925\n",
      "Train Epoch: 6 [15000/60000 (25%)]\tLoss: 0.412837\n",
      "Train Epoch: 6 [16000/60000 (27%)]\tLoss: 0.469165\n",
      "Train Epoch: 6 [17000/60000 (28%)]\tLoss: 0.497688\n",
      "Train Epoch: 6 [18000/60000 (30%)]\tLoss: 0.614967\n",
      "Train Epoch: 6 [19000/60000 (32%)]\tLoss: 0.515794\n",
      "Train Epoch: 6 [20000/60000 (33%)]\tLoss: 0.415157\n",
      "Train Epoch: 6 [21000/60000 (35%)]\tLoss: 0.362121\n",
      "Train Epoch: 6 [22000/60000 (37%)]\tLoss: 0.436579\n",
      "Train Epoch: 6 [23000/60000 (38%)]\tLoss: 0.509502\n",
      "Train Epoch: 6 [24000/60000 (40%)]\tLoss: 0.252915\n",
      "Train Epoch: 6 [25000/60000 (42%)]\tLoss: 0.538555\n",
      "Train Epoch: 6 [26000/60000 (43%)]\tLoss: 0.376534\n",
      "Train Epoch: 6 [27000/60000 (45%)]\tLoss: 0.526281\n",
      "Train Epoch: 6 [28000/60000 (47%)]\tLoss: 0.440226\n",
      "Train Epoch: 6 [29000/60000 (48%)]\tLoss: 0.525500\n",
      "Train Epoch: 6 [30000/60000 (50%)]\tLoss: 0.336388\n",
      "Train Epoch: 6 [31000/60000 (52%)]\tLoss: 0.351585\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.378877\n",
      "Train Epoch: 6 [33000/60000 (55%)]\tLoss: 0.273458\n",
      "Train Epoch: 6 [34000/60000 (57%)]\tLoss: 0.448987\n",
      "Train Epoch: 6 [35000/60000 (58%)]\tLoss: 0.279114\n",
      "Train Epoch: 6 [36000/60000 (60%)]\tLoss: 0.347478\n",
      "Train Epoch: 6 [37000/60000 (62%)]\tLoss: 0.429012\n",
      "Train Epoch: 6 [38000/60000 (63%)]\tLoss: 0.322030\n",
      "Train Epoch: 6 [39000/60000 (65%)]\tLoss: 0.446076\n",
      "Train Epoch: 6 [40000/60000 (67%)]\tLoss: 0.299856\n",
      "Train Epoch: 6 [41000/60000 (68%)]\tLoss: 0.481334\n",
      "Train Epoch: 6 [42000/60000 (70%)]\tLoss: 0.709636\n",
      "Train Epoch: 6 [43000/60000 (72%)]\tLoss: 0.514027\n",
      "Train Epoch: 6 [44000/60000 (73%)]\tLoss: 0.363575\n",
      "Train Epoch: 6 [45000/60000 (75%)]\tLoss: 0.346608\n",
      "Train Epoch: 6 [46000/60000 (77%)]\tLoss: 0.439002\n",
      "Train Epoch: 6 [47000/60000 (78%)]\tLoss: 0.627519\n",
      "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.437068\n",
      "Train Epoch: 6 [49000/60000 (82%)]\tLoss: 0.307274\n",
      "Train Epoch: 6 [50000/60000 (83%)]\tLoss: 0.245308\n",
      "Train Epoch: 6 [51000/60000 (85%)]\tLoss: 0.415195\n",
      "Train Epoch: 6 [52000/60000 (87%)]\tLoss: 0.371226\n",
      "Train Epoch: 6 [53000/60000 (88%)]\tLoss: 0.446061\n",
      "Train Epoch: 6 [54000/60000 (90%)]\tLoss: 0.340916\n",
      "Train Epoch: 6 [55000/60000 (92%)]\tLoss: 0.335440\n",
      "Train Epoch: 6 [56000/60000 (93%)]\tLoss: 0.514900\n",
      "Train Epoch: 6 [57000/60000 (95%)]\tLoss: 0.540560\n",
      "Train Epoch: 6 [58000/60000 (97%)]\tLoss: 0.444014\n",
      "Train Epoch: 6 [59000/60000 (98%)]\tLoss: 0.432993\n",
      "\n",
      "Test set: Average loss: 0.0043, Accuracy: 8530/10000 (85%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.561416\n",
      "Train Epoch: 7 [1000/60000 (2%)]\tLoss: 0.457649\n",
      "Train Epoch: 7 [2000/60000 (3%)]\tLoss: 0.403644\n",
      "Train Epoch: 7 [3000/60000 (5%)]\tLoss: 0.332237\n",
      "Train Epoch: 7 [4000/60000 (7%)]\tLoss: 0.355698\n",
      "Train Epoch: 7 [5000/60000 (8%)]\tLoss: 0.413136\n",
      "Train Epoch: 7 [6000/60000 (10%)]\tLoss: 0.439387\n",
      "Train Epoch: 7 [7000/60000 (12%)]\tLoss: 0.398813\n",
      "Train Epoch: 7 [8000/60000 (13%)]\tLoss: 0.315580\n",
      "Train Epoch: 7 [9000/60000 (15%)]\tLoss: 0.281910\n",
      "Train Epoch: 7 [10000/60000 (17%)]\tLoss: 0.392858\n",
      "Train Epoch: 7 [11000/60000 (18%)]\tLoss: 0.605896\n",
      "Train Epoch: 7 [12000/60000 (20%)]\tLoss: 0.294361\n",
      "Train Epoch: 7 [13000/60000 (22%)]\tLoss: 0.182261\n",
      "Train Epoch: 7 [14000/60000 (23%)]\tLoss: 0.268231\n",
      "Train Epoch: 7 [15000/60000 (25%)]\tLoss: 0.444347\n",
      "Train Epoch: 7 [16000/60000 (27%)]\tLoss: 0.372897\n",
      "Train Epoch: 7 [17000/60000 (28%)]\tLoss: 0.315756\n",
      "Train Epoch: 7 [18000/60000 (30%)]\tLoss: 0.348314\n",
      "Train Epoch: 7 [19000/60000 (32%)]\tLoss: 0.421861\n",
      "Train Epoch: 7 [20000/60000 (33%)]\tLoss: 0.376775\n",
      "Train Epoch: 7 [21000/60000 (35%)]\tLoss: 0.475539\n",
      "Train Epoch: 7 [22000/60000 (37%)]\tLoss: 0.428365\n",
      "Train Epoch: 7 [23000/60000 (38%)]\tLoss: 0.430900\n",
      "Train Epoch: 7 [24000/60000 (40%)]\tLoss: 0.352382\n",
      "Train Epoch: 7 [25000/60000 (42%)]\tLoss: 0.290017\n",
      "Train Epoch: 7 [26000/60000 (43%)]\tLoss: 0.378241\n",
      "Train Epoch: 7 [27000/60000 (45%)]\tLoss: 0.269361\n",
      "Train Epoch: 7 [28000/60000 (47%)]\tLoss: 0.435343\n",
      "Train Epoch: 7 [29000/60000 (48%)]\tLoss: 0.398891\n",
      "Train Epoch: 7 [30000/60000 (50%)]\tLoss: 0.466179\n",
      "Train Epoch: 7 [31000/60000 (52%)]\tLoss: 0.408213\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.486003\n",
      "Train Epoch: 7 [33000/60000 (55%)]\tLoss: 0.317457\n",
      "Train Epoch: 7 [34000/60000 (57%)]\tLoss: 0.448800\n",
      "Train Epoch: 7 [35000/60000 (58%)]\tLoss: 0.367774\n",
      "Train Epoch: 7 [36000/60000 (60%)]\tLoss: 0.415596\n",
      "Train Epoch: 7 [37000/60000 (62%)]\tLoss: 0.228265\n",
      "Train Epoch: 7 [38000/60000 (63%)]\tLoss: 0.436025\n",
      "Train Epoch: 7 [39000/60000 (65%)]\tLoss: 0.298567\n",
      "Train Epoch: 7 [40000/60000 (67%)]\tLoss: 0.430419\n",
      "Train Epoch: 7 [41000/60000 (68%)]\tLoss: 0.450540\n",
      "Train Epoch: 7 [42000/60000 (70%)]\tLoss: 0.401973\n",
      "Train Epoch: 7 [43000/60000 (72%)]\tLoss: 0.445392\n",
      "Train Epoch: 7 [44000/60000 (73%)]\tLoss: 0.462242\n",
      "Train Epoch: 7 [45000/60000 (75%)]\tLoss: 0.436518\n",
      "Train Epoch: 7 [46000/60000 (77%)]\tLoss: 0.380928\n",
      "Train Epoch: 7 [47000/60000 (78%)]\tLoss: 0.391262\n",
      "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.378228\n",
      "Train Epoch: 7 [49000/60000 (82%)]\tLoss: 0.402794\n",
      "Train Epoch: 7 [50000/60000 (83%)]\tLoss: 0.594860\n",
      "Train Epoch: 7 [51000/60000 (85%)]\tLoss: 0.456976\n",
      "Train Epoch: 7 [52000/60000 (87%)]\tLoss: 0.280825\n",
      "Train Epoch: 7 [53000/60000 (88%)]\tLoss: 0.351794\n",
      "Train Epoch: 7 [54000/60000 (90%)]\tLoss: 0.542466\n",
      "Train Epoch: 7 [55000/60000 (92%)]\tLoss: 0.473661\n",
      "Train Epoch: 7 [56000/60000 (93%)]\tLoss: 0.299853\n",
      "Train Epoch: 7 [57000/60000 (95%)]\tLoss: 0.477459\n",
      "Train Epoch: 7 [58000/60000 (97%)]\tLoss: 0.387576\n",
      "Train Epoch: 7 [59000/60000 (98%)]\tLoss: 0.437908\n",
      "\n",
      "Test set: Average loss: 0.0041, Accuracy: 8562/10000 (86%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.430561\n",
      "Train Epoch: 8 [1000/60000 (2%)]\tLoss: 0.400694\n",
      "Train Epoch: 8 [2000/60000 (3%)]\tLoss: 0.495265\n",
      "Train Epoch: 8 [3000/60000 (5%)]\tLoss: 0.339488\n",
      "Train Epoch: 8 [4000/60000 (7%)]\tLoss: 0.397632\n",
      "Train Epoch: 8 [5000/60000 (8%)]\tLoss: 0.410418\n",
      "Train Epoch: 8 [6000/60000 (10%)]\tLoss: 0.441900\n",
      "Train Epoch: 8 [7000/60000 (12%)]\tLoss: 0.244641\n",
      "Train Epoch: 8 [8000/60000 (13%)]\tLoss: 0.560065\n",
      "Train Epoch: 8 [9000/60000 (15%)]\tLoss: 0.482195\n",
      "Train Epoch: 8 [10000/60000 (17%)]\tLoss: 0.361650\n",
      "Train Epoch: 8 [11000/60000 (18%)]\tLoss: 0.460962\n",
      "Train Epoch: 8 [12000/60000 (20%)]\tLoss: 0.433177\n",
      "Train Epoch: 8 [13000/60000 (22%)]\tLoss: 0.361976\n",
      "Train Epoch: 8 [14000/60000 (23%)]\tLoss: 0.362618\n",
      "Train Epoch: 8 [15000/60000 (25%)]\tLoss: 0.342402\n",
      "Train Epoch: 8 [16000/60000 (27%)]\tLoss: 0.409275\n",
      "Train Epoch: 8 [17000/60000 (28%)]\tLoss: 0.469514\n",
      "Train Epoch: 8 [18000/60000 (30%)]\tLoss: 0.624438\n",
      "Train Epoch: 8 [19000/60000 (32%)]\tLoss: 0.328450\n",
      "Train Epoch: 8 [20000/60000 (33%)]\tLoss: 0.463529\n",
      "Train Epoch: 8 [21000/60000 (35%)]\tLoss: 0.333466\n",
      "Train Epoch: 8 [22000/60000 (37%)]\tLoss: 0.375198\n",
      "Train Epoch: 8 [23000/60000 (38%)]\tLoss: 0.559361\n",
      "Train Epoch: 8 [24000/60000 (40%)]\tLoss: 0.410747\n",
      "Train Epoch: 8 [25000/60000 (42%)]\tLoss: 0.426985\n",
      "Train Epoch: 8 [26000/60000 (43%)]\tLoss: 0.324181\n",
      "Train Epoch: 8 [27000/60000 (45%)]\tLoss: 0.334578\n",
      "Train Epoch: 8 [28000/60000 (47%)]\tLoss: 0.389569\n",
      "Train Epoch: 8 [29000/60000 (48%)]\tLoss: 0.321836\n",
      "Train Epoch: 8 [30000/60000 (50%)]\tLoss: 0.464649\n",
      "Train Epoch: 8 [31000/60000 (52%)]\tLoss: 0.575622\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.331359\n",
      "Train Epoch: 8 [33000/60000 (55%)]\tLoss: 0.420256\n",
      "Train Epoch: 8 [34000/60000 (57%)]\tLoss: 0.327685\n",
      "Train Epoch: 8 [35000/60000 (58%)]\tLoss: 0.488115\n",
      "Train Epoch: 8 [36000/60000 (60%)]\tLoss: 0.401113\n",
      "Train Epoch: 8 [37000/60000 (62%)]\tLoss: 0.200585\n",
      "Train Epoch: 8 [38000/60000 (63%)]\tLoss: 0.488377\n",
      "Train Epoch: 8 [39000/60000 (65%)]\tLoss: 0.506950\n",
      "Train Epoch: 8 [40000/60000 (67%)]\tLoss: 0.470907\n",
      "Train Epoch: 8 [41000/60000 (68%)]\tLoss: 0.485465\n",
      "Train Epoch: 8 [42000/60000 (70%)]\tLoss: 0.366181\n",
      "Train Epoch: 8 [43000/60000 (72%)]\tLoss: 0.481237\n",
      "Train Epoch: 8 [44000/60000 (73%)]\tLoss: 0.417328\n",
      "Train Epoch: 8 [45000/60000 (75%)]\tLoss: 0.298584\n",
      "Train Epoch: 8 [46000/60000 (77%)]\tLoss: 0.394138\n",
      "Train Epoch: 8 [47000/60000 (78%)]\tLoss: 0.521235\n",
      "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.389053\n",
      "Train Epoch: 8 [49000/60000 (82%)]\tLoss: 0.485183\n",
      "Train Epoch: 8 [50000/60000 (83%)]\tLoss: 0.438067\n",
      "Train Epoch: 8 [51000/60000 (85%)]\tLoss: 0.319988\n",
      "Train Epoch: 8 [52000/60000 (87%)]\tLoss: 0.411635\n",
      "Train Epoch: 8 [53000/60000 (88%)]\tLoss: 0.304278\n",
      "Train Epoch: 8 [54000/60000 (90%)]\tLoss: 0.483410\n",
      "Train Epoch: 8 [55000/60000 (92%)]\tLoss: 0.364748\n",
      "Train Epoch: 8 [56000/60000 (93%)]\tLoss: 0.430535\n",
      "Train Epoch: 8 [57000/60000 (95%)]\tLoss: 0.449078\n",
      "Train Epoch: 8 [58000/60000 (97%)]\tLoss: 0.371009\n",
      "Train Epoch: 8 [59000/60000 (98%)]\tLoss: 0.303327\n",
      "\n",
      "Test set: Average loss: 0.0040, Accuracy: 8602/10000 (86%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.424654\n",
      "Train Epoch: 9 [1000/60000 (2%)]\tLoss: 0.669275\n",
      "Train Epoch: 9 [2000/60000 (3%)]\tLoss: 0.422305\n",
      "Train Epoch: 9 [3000/60000 (5%)]\tLoss: 0.405172\n",
      "Train Epoch: 9 [4000/60000 (7%)]\tLoss: 0.365996\n",
      "Train Epoch: 9 [5000/60000 (8%)]\tLoss: 0.344299\n",
      "Train Epoch: 9 [6000/60000 (10%)]\tLoss: 0.322333\n",
      "Train Epoch: 9 [7000/60000 (12%)]\tLoss: 0.415403\n",
      "Train Epoch: 9 [8000/60000 (13%)]\tLoss: 0.487598\n",
      "Train Epoch: 9 [9000/60000 (15%)]\tLoss: 0.482295\n",
      "Train Epoch: 9 [10000/60000 (17%)]\tLoss: 0.490033\n",
      "Train Epoch: 9 [11000/60000 (18%)]\tLoss: 0.393512\n",
      "Train Epoch: 9 [12000/60000 (20%)]\tLoss: 0.314537\n",
      "Train Epoch: 9 [13000/60000 (22%)]\tLoss: 0.360228\n",
      "Train Epoch: 9 [14000/60000 (23%)]\tLoss: 0.356864\n",
      "Train Epoch: 9 [15000/60000 (25%)]\tLoss: 0.321175\n",
      "Train Epoch: 9 [16000/60000 (27%)]\tLoss: 0.333945\n",
      "Train Epoch: 9 [17000/60000 (28%)]\tLoss: 0.505863\n",
      "Train Epoch: 9 [18000/60000 (30%)]\tLoss: 0.392870\n",
      "Train Epoch: 9 [19000/60000 (32%)]\tLoss: 0.430173\n",
      "Train Epoch: 9 [20000/60000 (33%)]\tLoss: 0.226298\n",
      "Train Epoch: 9 [21000/60000 (35%)]\tLoss: 0.392874\n",
      "Train Epoch: 9 [22000/60000 (37%)]\tLoss: 0.355570\n",
      "Train Epoch: 9 [23000/60000 (38%)]\tLoss: 0.299785\n",
      "Train Epoch: 9 [24000/60000 (40%)]\tLoss: 0.370135\n",
      "Train Epoch: 9 [25000/60000 (42%)]\tLoss: 0.405718\n",
      "Train Epoch: 9 [26000/60000 (43%)]\tLoss: 0.425720\n",
      "Train Epoch: 9 [27000/60000 (45%)]\tLoss: 0.315942\n",
      "Train Epoch: 9 [28000/60000 (47%)]\tLoss: 0.379923\n",
      "Train Epoch: 9 [29000/60000 (48%)]\tLoss: 0.420500\n",
      "Train Epoch: 9 [30000/60000 (50%)]\tLoss: 0.412604\n",
      "Train Epoch: 9 [31000/60000 (52%)]\tLoss: 0.540932\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.498171\n",
      "Train Epoch: 9 [33000/60000 (55%)]\tLoss: 0.472735\n",
      "Train Epoch: 9 [34000/60000 (57%)]\tLoss: 0.338267\n",
      "Train Epoch: 9 [35000/60000 (58%)]\tLoss: 0.368462\n",
      "Train Epoch: 9 [36000/60000 (60%)]\tLoss: 0.333904\n",
      "Train Epoch: 9 [37000/60000 (62%)]\tLoss: 0.428894\n",
      "Train Epoch: 9 [38000/60000 (63%)]\tLoss: 0.416259\n",
      "Train Epoch: 9 [39000/60000 (65%)]\tLoss: 0.231896\n",
      "Train Epoch: 9 [40000/60000 (67%)]\tLoss: 0.438444\n",
      "Train Epoch: 9 [41000/60000 (68%)]\tLoss: 0.323646\n",
      "Train Epoch: 9 [42000/60000 (70%)]\tLoss: 0.341756\n",
      "Train Epoch: 9 [43000/60000 (72%)]\tLoss: 0.404130\n",
      "Train Epoch: 9 [44000/60000 (73%)]\tLoss: 0.291756\n",
      "Train Epoch: 9 [45000/60000 (75%)]\tLoss: 0.318556\n",
      "Train Epoch: 9 [46000/60000 (77%)]\tLoss: 0.383977\n",
      "Train Epoch: 9 [47000/60000 (78%)]\tLoss: 0.301814\n",
      "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.463627\n",
      "Train Epoch: 9 [49000/60000 (82%)]\tLoss: 0.346885\n",
      "Train Epoch: 9 [50000/60000 (83%)]\tLoss: 0.444543\n",
      "Train Epoch: 9 [51000/60000 (85%)]\tLoss: 0.334190\n",
      "Train Epoch: 9 [52000/60000 (87%)]\tLoss: 0.374286\n",
      "Train Epoch: 9 [53000/60000 (88%)]\tLoss: 0.408166\n",
      "Train Epoch: 9 [54000/60000 (90%)]\tLoss: 0.390715\n",
      "Train Epoch: 9 [55000/60000 (92%)]\tLoss: 0.221166\n",
      "Train Epoch: 9 [56000/60000 (93%)]\tLoss: 0.322279\n",
      "Train Epoch: 9 [57000/60000 (95%)]\tLoss: 0.482798\n",
      "Train Epoch: 9 [58000/60000 (97%)]\tLoss: 0.331352\n",
      "Train Epoch: 9 [59000/60000 (98%)]\tLoss: 0.537729\n",
      "\n",
      "Test set: Average loss: 0.0039, Accuracy: 8631/10000 (86%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.334207\n",
      "Train Epoch: 10 [1000/60000 (2%)]\tLoss: 0.428500\n",
      "Train Epoch: 10 [2000/60000 (3%)]\tLoss: 0.253566\n",
      "Train Epoch: 10 [3000/60000 (5%)]\tLoss: 0.240578\n",
      "Train Epoch: 10 [4000/60000 (7%)]\tLoss: 0.446903\n",
      "Train Epoch: 10 [5000/60000 (8%)]\tLoss: 0.274010\n",
      "Train Epoch: 10 [6000/60000 (10%)]\tLoss: 0.322364\n",
      "Train Epoch: 10 [7000/60000 (12%)]\tLoss: 0.421258\n",
      "Train Epoch: 10 [8000/60000 (13%)]\tLoss: 0.463995\n",
      "Train Epoch: 10 [9000/60000 (15%)]\tLoss: 0.419067\n",
      "Train Epoch: 10 [10000/60000 (17%)]\tLoss: 0.332878\n",
      "Train Epoch: 10 [11000/60000 (18%)]\tLoss: 0.375838\n",
      "Train Epoch: 10 [12000/60000 (20%)]\tLoss: 0.309341\n",
      "Train Epoch: 10 [13000/60000 (22%)]\tLoss: 0.505887\n",
      "Train Epoch: 10 [14000/60000 (23%)]\tLoss: 0.312574\n",
      "Train Epoch: 10 [15000/60000 (25%)]\tLoss: 0.354245\n",
      "Train Epoch: 10 [16000/60000 (27%)]\tLoss: 0.464285\n",
      "Train Epoch: 10 [17000/60000 (28%)]\tLoss: 0.325500\n",
      "Train Epoch: 10 [18000/60000 (30%)]\tLoss: 0.502095\n",
      "Train Epoch: 10 [19000/60000 (32%)]\tLoss: 0.338370\n",
      "Train Epoch: 10 [20000/60000 (33%)]\tLoss: 0.419253\n",
      "Train Epoch: 10 [21000/60000 (35%)]\tLoss: 0.554421\n",
      "Train Epoch: 10 [22000/60000 (37%)]\tLoss: 0.419572\n",
      "Train Epoch: 10 [23000/60000 (38%)]\tLoss: 0.375549\n",
      "Train Epoch: 10 [24000/60000 (40%)]\tLoss: 0.462108\n",
      "Train Epoch: 10 [25000/60000 (42%)]\tLoss: 0.337417\n",
      "Train Epoch: 10 [26000/60000 (43%)]\tLoss: 0.312060\n",
      "Train Epoch: 10 [27000/60000 (45%)]\tLoss: 0.266574\n",
      "Train Epoch: 10 [28000/60000 (47%)]\tLoss: 0.446485\n",
      "Train Epoch: 10 [29000/60000 (48%)]\tLoss: 0.318099\n",
      "Train Epoch: 10 [30000/60000 (50%)]\tLoss: 0.364251\n",
      "Train Epoch: 10 [31000/60000 (52%)]\tLoss: 0.416111\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.430329\n",
      "Train Epoch: 10 [33000/60000 (55%)]\tLoss: 0.344166\n",
      "Train Epoch: 10 [34000/60000 (57%)]\tLoss: 0.363127\n",
      "Train Epoch: 10 [35000/60000 (58%)]\tLoss: 0.410985\n",
      "Train Epoch: 10 [36000/60000 (60%)]\tLoss: 0.428255\n",
      "Train Epoch: 10 [37000/60000 (62%)]\tLoss: 0.473733\n",
      "Train Epoch: 10 [38000/60000 (63%)]\tLoss: 0.387254\n",
      "Train Epoch: 10 [39000/60000 (65%)]\tLoss: 0.553580\n",
      "Train Epoch: 10 [40000/60000 (67%)]\tLoss: 0.337052\n",
      "Train Epoch: 10 [41000/60000 (68%)]\tLoss: 0.320261\n",
      "Train Epoch: 10 [42000/60000 (70%)]\tLoss: 0.408704\n",
      "Train Epoch: 10 [43000/60000 (72%)]\tLoss: 0.342337\n",
      "Train Epoch: 10 [44000/60000 (73%)]\tLoss: 0.385821\n",
      "Train Epoch: 10 [45000/60000 (75%)]\tLoss: 0.209357\n",
      "Train Epoch: 10 [46000/60000 (77%)]\tLoss: 0.589294\n",
      "Train Epoch: 10 [47000/60000 (78%)]\tLoss: 0.376526\n",
      "Train Epoch: 10 [48000/60000 (80%)]\tLoss: 0.442347\n",
      "Train Epoch: 10 [49000/60000 (82%)]\tLoss: 0.242155\n",
      "Train Epoch: 10 [50000/60000 (83%)]\tLoss: 0.418041\n",
      "Train Epoch: 10 [51000/60000 (85%)]\tLoss: 0.414256\n",
      "Train Epoch: 10 [52000/60000 (87%)]\tLoss: 0.282674\n",
      "Train Epoch: 10 [53000/60000 (88%)]\tLoss: 0.321657\n",
      "Train Epoch: 10 [54000/60000 (90%)]\tLoss: 0.355236\n",
      "Train Epoch: 10 [55000/60000 (92%)]\tLoss: 0.244189\n",
      "Train Epoch: 10 [56000/60000 (93%)]\tLoss: 0.377985\n",
      "Train Epoch: 10 [57000/60000 (95%)]\tLoss: 0.444923\n",
      "Train Epoch: 10 [58000/60000 (97%)]\tLoss: 0.317840\n",
      "Train Epoch: 10 [59000/60000 (98%)]\tLoss: 0.421592\n",
      "\n",
      "Test set: Average loss: 0.0038, Accuracy: 8649/10000 (86%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, args['epochs'] + 1):\n",
    "    train(epoch)\n",
    "    test()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1OipUVawbYcr"
   },
   "source": [
    "## 2. Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GA50s29XbYcs"
   },
   "source": [
    "### 1. Please use other activation functions, e.g., sigmoid, tanh, and then plot the training loss and testing accuracy. \n",
    "\n",
    "When plotting the training loss, the x-axis is iteration and the y-axis is training loss. When plotting the testing accuracy,  the x-axis is epoch and the y-axis is the training loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SCUF04MYbYcs"
   },
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j-ThwUJxbYcs"
   },
   "source": [
    "### 2. Please use different layers in the model, e.g., 1 layer, 5 layers, 10 layers,  and then plot the training loss and testing accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D2fTAFyEbYcs"
   },
   "outputs": [],
   "source": [
    "# your code"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Lab10.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
