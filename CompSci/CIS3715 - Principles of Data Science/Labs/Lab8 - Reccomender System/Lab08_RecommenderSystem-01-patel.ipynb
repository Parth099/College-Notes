{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 8: Recommender System\n",
    "\n",
    "In this assignment, we will study how to do user-based collaborative filtering and item-based collaborative filtering. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset\n",
    "\n",
    "In this assignment, we will use MovieLens-100K dataset. It includes about 100,000 ratings from 1000 users on 1700 movies.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(943, 1664)\n",
      "(943, 1664)\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "\n",
    "# 1. load data\n",
    "user_ratings_train = pd.read_csv('./ml-100k/u1.base',\n",
    "                            sep='\\t',names=['user_id','movie_id','rating'], usecols=[0,1,2])\n",
    "\n",
    "user_ratings_test = pd.read_csv('./ml-100k/u1.test',\n",
    "                            sep='\\t',names=['user_id','movie_id','rating'], usecols=[0,1,2])\n",
    "\n",
    "movie_info =  pd.read_csv('./ml-100k/u.item', \n",
    "                          sep='|', names=['movie_id','title'], usecols=[0,1],\n",
    "                          encoding=\"ISO-8859-1\")\n",
    "\n",
    "user_ratings_train = pd.merge(movie_info, user_ratings_train)\n",
    "user_ratings_test = pd.merge(movie_info, user_ratings_test)\n",
    "\n",
    "# 2. get the rating matrix. Each row is a user, and each column is a movie.\n",
    "user_ratings_train = user_ratings_train.pivot_table(index=['user_id'],\n",
    "                                        columns=['title'],\n",
    "                                        values='rating')\n",
    "\n",
    "user_ratings_test = user_ratings_test.pivot_table(index=['user_id'],\n",
    "                                        columns=['title'],\n",
    "                                        values='rating')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "user_ratings_train = user_ratings_train.reindex(\n",
    "                            index=user_ratings_train.index.union(user_ratings_test.index), \n",
    "                            columns=user_ratings_train.columns.union(user_ratings_test.columns) )\n",
    "\n",
    "user_ratings_test = user_ratings_test.reindex(\n",
    "                            index=user_ratings_train.index.union(user_ratings_test.index), \n",
    "                            columns=user_ratings_train.columns.union(user_ratings_test.columns) )\n",
    "\n",
    "print(user_ratings_train.shape)\n",
    "print(user_ratings_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1. User-based CF\n",
    "\n",
    "* Use pearson correlation to get the similarity between different users.\n",
    "* Based on the obtained similarity score, predict the ratings. You can use 5 nearest neighbors or 10 nearest neighbors.\n",
    "* Compute MAE for the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to replace nan values since NN doesnt support NaN values\n",
    "mean_ratings_by_user = user_ratings_train.mean(axis=1)\n",
    "user_ratings_train_nan_filled = user_ratings_train.T.fillna(mean_ratings_by_user).T # fill magic i found on SOF\n",
    "\n",
    "# calc pearson value for user\n",
    "network = user_ratings_train_nan_filled.T.corr(method='pearson').values\n",
    "\n",
    "# fit Nearest Neighbors with network data\n",
    "USER_CF_NEIGHBOR_COUNT = 10\n",
    "NearestNeighborsModel = NearestNeighbors(n_neighbors=USER_CF_NEIGHBOR_COUNT).fit(network)\n",
    "\n",
    "# run NN on the self dataset signified by X=None\n",
    "neighbors_distance, neighbors_ind = NearestNeighborsModel.kneighbors(X=None)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for User-based CF is 0.8051374780803943 with nneighbors=10\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# preprare train and test matrices\n",
    "user_data_train = user_ratings_train_nan_filled.values\n",
    "user_data_test  = user_ratings_test.values\n",
    "\n",
    "# input for mean_absolute_error\n",
    "truth, pred  = [], []\n",
    "\n",
    "# loop over each value of the test set\n",
    "for user_id, user_ratings in enumerate(user_data_test):\n",
    "    for video_id, video_rating in enumerate(user_ratings):\n",
    "        # ignore null test ratings\n",
    "        if np.isnan(user_data_test[user_id, video_id]): continue\n",
    "        \n",
    "        # get the neighbors of current user to predict\n",
    "        neighbors = neighbors_ind[user_id]\n",
    "        \n",
    "        # get the ratings given by the neighbors via train\n",
    "        neighbor_ratings = user_data_train[neighbors]\n",
    "        \n",
    "        # get rating for the video\n",
    "        video_ratings = neighbor_ratings[:, video_id]\n",
    "        \n",
    "        # get biases for each user\n",
    "        biases    = mean_ratings_by_user.values[neighbors]\n",
    "        self_bias = mean_ratings_by_user.values[user_id]\n",
    "        \n",
    "        # get simarity for each user\n",
    "        sim_scores = network[user_id][neighbors]\n",
    "        \n",
    "        # compute full score\n",
    "        score = self_bias + (np.sum((np.multiply(sim_scores, video_ratings - biases))) / np.sum(sim_scores))\n",
    "        \n",
    "        # save to compute error later\n",
    "        truth.append(user_data_test[user_id, video_id])\n",
    "        pred.append(score)\n",
    "        \n",
    "\n",
    "MAE = mean_absolute_error(truth, pred)\n",
    "print(f'MAE for User-based CF is {MAE} with nneighbors={USER_CF_NEIGHBOR_COUNT}')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2. Item-based CF\n",
    "* Use cosine similarity to get the similarity between different items.\n",
    "* Based on the obtained similarity score, predict the ratings. You can use 5 nearest neighbors or 10 nearest neighbors.\n",
    "* Compute MAE for the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item data shape after dropping movies nobody watched: (1633, 943)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "\n",
    "# transpose to give features to movies to use for pred\n",
    "items_data_train = user_ratings_train.T\n",
    "\n",
    "# fill averages with the mean rating received for that movie. \n",
    "item_data_train_mean_filled = items_data_train.T.fillna(items_data_train.mean(axis=1)).T\n",
    "\n",
    "# remove rows with no data\n",
    "movies_no_body_watched = []\n",
    "num_entries_still_missing = item_data_train_mean_filled.isna().sum(axis=1)\n",
    "\n",
    "# scan for movies with no ratings\n",
    "for movie_name, num_missing in num_entries_still_missing.items():\n",
    "    if num_missing: movies_no_body_watched.append(movie_name)\n",
    "        \n",
    "# drop them from the model\n",
    "item_data_train_mean_filled_valid_movies = item_data_train_mean_filled.drop(movies_no_body_watched)\n",
    "print(f\"Item data shape after dropping movies nobody watched: {item_data_train_mean_filled_valid_movies.shape}\")\n",
    "\n",
    "# use cosine_similarity from sklearn and feed it to pandas to perform corr\n",
    "network = pairwise_distances(item_data_train_mean_filled_valid_movies, metric='cosine')\n",
    "\n",
    "# create model based on corrs between movies\n",
    "ITEM_FC_NEIGHBOR_COUNT = 10\n",
    "ItemNearestNeighborsModel = NearestNeighbors(n_neighbors=ITEM_FC_NEIGHBOR_COUNT).fit(item_data_train_mean_filled_valid_movies.values)\n",
    "dists, nbrs = ItemNearestNeighborsModel.kneighbors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full dataset\n",
    "item_data_test = user_ratings_test.T\n",
    "\n",
    "# dataset with movies nobody as rated removed\n",
    "item_data_test_valid_movies = item_data_test.drop(movies_no_body_watched).values\n",
    "\n",
    "# ref to a .values numpy array for speed\n",
    "item_data_train_mean_filled_valid_movies_values = item_data_train_mean_filled_valid_movies.values\n",
    "\n",
    "# input for mean_absolute_error\n",
    "truth, pred  = [], []\n",
    "\n",
    "# loop over each value of the test set\n",
    "for video_id, test_user_ratings in enumerate(item_data_test_valid_movies):\n",
    "    \n",
    "    # get item neighbors of given movie\n",
    "    neighbors = nbrs[video_id] # this is the neigbhor hood of similar movies\n",
    "    \n",
    "    for user_id, truth_val in enumerate(test_user_ratings):\n",
    "        # pass over null test values\n",
    "        if np.isnan(item_data_test_valid_movies[video_id, user_id]): continue\n",
    "            \n",
    "        # save truth value\n",
    "        truth.append(truth_val)\n",
    "        \n",
    "        # get ratings fron neighbors\n",
    "        given_ratings = item_data_train_mean_filled_valid_movies_values[neighbors, user_id]\n",
    "        \n",
    "        # get correlations\n",
    "        sim_scores = network[video_id][neighbors]\n",
    "        \n",
    "        # get user ratings for neighbors\n",
    "        user_ratings = item_data_train_mean_filled_valid_movies_values[neighbors, user_id]\n",
    "        \n",
    "        # calc pred\n",
    "        sum_scores = np.sum(sim_scores)\n",
    "        \n",
    "        # if the sum of scores (denom) is non zero assign a score other wise just assign average of user ratings\n",
    "        if sum_scores:\n",
    "            rating_pred = np.sum(np.multiply(sim_scores, user_ratings)) / sum_scores\n",
    "        else:\n",
    "            rating_pred = mean_ratings_by_user[user_id]\n",
    "        \n",
    "        pred.append(rating_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for Item-based CF is 0.8257884888390413 with nneighbors=10\n"
     ]
    }
   ],
   "source": [
    "MAE = mean_absolute_error(truth, pred)\n",
    "print(f'MAE for Item-based CF is {MAE} with nneighbors={ITEM_FC_NEIGHBOR_COUNT}')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
